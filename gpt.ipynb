{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24901ec0-8068-493d-ba74-1b249dd008bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T02:46:39.830709Z",
     "iopub.status.busy": "2025-12-08T02:46:39.830288Z",
     "iopub.status.idle": "2025-12-08T02:46:39.834595Z",
     "shell.execute_reply": "2025-12-08T02:46:39.833646Z",
     "shell.execute_reply.started": "2025-12-08T02:46:39.830693Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edcef166-3a33-457a-bcc1-dc5aa95cbcec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T02:11:39.998636Z",
     "iopub.status.busy": "2025-12-08T02:11:39.993888Z",
     "iopub.status.idle": "2025-12-08T02:11:40.392042Z",
     "shell.execute_reply": "2025-12-08T02:11:40.390481Z",
     "shell.execute_reply.started": "2025-12-08T02:11:39.998395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-12-07 21:11:40--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt’\n",
      "\n",
      "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
      "\n",
      "2025-12-07 21:11:40 (17.9 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca5c375f-85ba-4316-98e6-75c6c95be489",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T02:11:44.146797Z",
     "iopub.status.busy": "2025-12-08T02:11:44.146543Z",
     "iopub.status.idle": "2025-12-08T02:11:44.155933Z",
     "shell.execute_reply": "2025-12-08T02:11:44.154964Z",
     "shell.execute_reply.started": "2025-12-08T02:11:44.146778Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e3d15a0-4b6f-4060-97c5-bb92a30edb48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T02:14:30.538186Z",
     "iopub.status.busy": "2025-12-08T02:14:30.537292Z",
     "iopub.status.idle": "2025-12-08T02:14:33.021459Z",
     "shell.execute_reply": "2025-12-08T02:14:33.020103Z",
     "shell.execute_reply.started": "2025-12-08T02:14:30.538138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.12.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in ./venv/lib/python3.12/site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2025.11.12)\n",
      "Downloading tiktoken-0.12.0-cp312-cp312-manylinux_2_28_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, tiktoken\n",
      "Successfully installed regex-2025.11.3 tiktoken-0.12.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6f0e8ed-8e3a-4a21-8d15-057b3c36c556",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T02:21:10.833537Z",
     "iopub.status.busy": "2025-12-08T02:21:10.833328Z",
     "iopub.status.idle": "2025-12-08T02:21:12.567950Z",
     "shell.execute_reply": "2025-12-08T02:21:12.566792Z",
     "shell.execute_reply.started": "2025-12-08T02:21:10.833521Z"
    }
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"o200k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a7ad2ac-8225-467c-9699-e88f847a3616",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T03:25:52.501051Z",
     "iopub.status.busy": "2025-12-09T03:25:52.500840Z",
     "iopub.status.idle": "2025-12-09T03:25:52.503899Z",
     "shell.execute_reply": "2025-12-09T03:25:52.502997Z",
     "shell.execute_reply.started": "2025-12-09T03:25:52.501036Z"
    }
   },
   "outputs": [],
   "source": [
    "# config\n",
    "block_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fec2aa32-4316-4142-9b9e-3af64c6ed61f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T03:25:23.000848Z",
     "iopub.status.busy": "2025-12-09T03:25:23.000665Z",
     "iopub.status.idle": "2025-12-09T03:25:23.193181Z",
     "shell.execute_reply": "2025-12-09T03:25:23.192268Z",
     "shell.execute_reply.started": "2025-12-09T03:25:23.000836Z"
    }
   },
   "outputs": [],
   "source": [
    "data = torch.tensor(enc.encode(text))\n",
    "train_data = data[:int(0.9*len(data))]\n",
    "test_data = data[int(0.9*len(data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d08585e5-1429-4b08-a6b7-6d14ea150649",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T03:25:53.544370Z",
     "iopub.status.busy": "2025-12-09T03:25:53.544187Z",
     "iopub.status.idle": "2025-12-09T03:25:53.547747Z",
     "shell.execute_reply": "2025-12-09T03:25:53.546864Z",
     "shell.execute_reply.started": "2025-12-09T03:25:53.544358Z"
    }
   },
   "outputs": [],
   "source": [
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - block_size - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\"x\": self.data[idx:idx+block_size], \"y\": self.data[idx+1:idx+block_size+1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d936a809-e30b-4adb-a577-61334d6ea6d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T03:25:53.956597Z",
     "iopub.status.busy": "2025-12-09T03:25:53.956411Z",
     "iopub.status.idle": "2025-12-09T03:25:53.959542Z",
     "shell.execute_reply": "2025-12-09T03:25:53.958703Z",
     "shell.execute_reply.started": "2025-12-09T03:25:53.956584Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = GPTDataset(train_data)\n",
    "test_ds = GPTDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1d69b4a-9369-4222-9f0e-735582651a22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T03:26:03.096904Z",
     "iopub.status.busy": "2025-12-09T03:26:03.096711Z",
     "iopub.status.idle": "2025-12-09T03:26:03.100118Z",
     "shell.execute_reply": "2025-12-09T03:26:03.099183Z",
     "shell.execute_reply.started": "2025-12-09T03:26:03.096886Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a48fc0b1-716f-430b-a63c-97c5ccea72d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T03:26:23.953685Z",
     "iopub.status.busy": "2025-12-09T03:26:23.953495Z",
     "iopub.status.idle": "2025-12-09T03:26:24.020352Z",
     "shell.execute_reply": "2025-12-09T03:26:24.019491Z",
     "shell.execute_reply.started": "2025-12-09T03:26:23.953673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[ 65865,    316,    261,  ...,    285,   5119,    461],\n",
      "        [    88,     25,    889,  ...,   1485,   6354,    289],\n",
      "        [  7994,    558,  16936,  ...,    198,   2886,  10143],\n",
      "        ...,\n",
      "        [120206,     11,    326,  ...,    395,    495,   4175],\n",
      "        [  1584,  81238,  84479,  ...,   9144,    540,    461],\n",
      "        [ 14347,   1280,    963,  ...,   2212,    873,     11]]), 'y': tensor([[   316,    261, 111761,  ...,   5119,    461, 104853],\n",
      "        [    25,    889,    922,  ...,   6354,    289,    412],\n",
      "        [   558,  16936,     11,  ...,   2886,  10143,   4465],\n",
      "        ...,\n",
      "        [    11,    326,   2242,  ...,    495,   4175,  37788],\n",
      "        [ 81238,  84479,    734,  ...,    540,    461,     82],\n",
      "        [  1280,    963,   3901,  ...,    873,     11,  17291]])}\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dl:\n",
    "    print(batch)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nn)",
   "language": "python",
   "name": "nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
